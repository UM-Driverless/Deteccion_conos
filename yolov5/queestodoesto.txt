Cada carpeta es un entrenamiento diferente
(Se puede ver el código con el que se hizo desde cada run en la pestaña de i p.e.:
https://wandb.ai/dhaniel/YOLOv5/runs/3h2n68fk/overview?workspace=user-dhaniel

1 clase

* cones-MIT (dataset MIT)
* cones-fine (dataset nuestro (1 clase) con finetune preentrenado en MIT)

3 clases

* cones-mixed-classes (dataset nuestro)
* cones-mixed-classes-pretrained (dataset nuestro con finetune preentrenado en MIT)
* cones-mixed-classes-pretrained-2 (dataset nuestro preentrenado en MIT pero sin finetune)

Yo probaría:

cones-fine (1 clase)
cones-mixed-classes (3 clases)

